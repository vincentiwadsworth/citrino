# ğŸ—ï¸ Arquitectura de Datos - MigraciÃ³n a PostgreSQL + PostGIS

DocumentaciÃ³n completa de la migraciÃ³n desde JSON centralizado a PostgreSQL + PostGIS basada en investigaciÃ³n experta de Tongyi.

---

## ğŸ¯ Resumen Ejecutivo

**DecisiÃ³n EstratÃ©gica**: MigraciÃ³n de archivos JSON a PostgreSQL + PostGIS
**Fuente**: InvestigaciÃ³n detallada con Tongyi (LLM especializado)
**Objetivo**: Resolver limitaciones de rendimiento, escalabilidad y consistencia
**Resultado Esperado**: Consultas geoespaciales de segundos â†’ milisegundos

### Beneficios Clave
- **Rendimiento**: ReducciÃ³n drÃ¡stica en tiempos de respuesta geoespacial
- **Escalabilidad**: Capacidad para 10x crecimiento sin degradaciÃ³n
- **Integridad**: Consistencia ACID con claves forÃ¡neas
- **Capacidades AnalÃ­ticas**: Consultas complejas relacionales + espaciales

---

## ğŸ“Š Estado Actual vs Propuesto

### Arquitectura Actual (JSON)
```
data/
â”œâ”€â”€ base_datos_relevamiento.json    # 1,588 propiedades
â””â”€â”€ guia_urbana_municipal_completa.json  # 4,777 servicios
```

**Limitaciones CrÃ­ticas**:
- Consultas O(nÃ—m): 7,585,876 cÃ¡lculos por bÃºsqueda
- Sin concurrencia en actualizaciones
- DuplicaciÃ³n de datos de agentes
- Performance: segundos por consulta geoespacial

### Arquitectura Propuesta (PostgreSQL + PostGIS)
```
PostgreSQL Database:
â”œâ”€â”€ agentes (tabla normalizada)
â”œâ”€â”€ propiedades (con coordenadas GEOGRAPHY)
â”œâ”€â”€ servicios (con Ã­ndices espaciales GIST)
â””â”€â”€ Ãndices optimizados (B-Tree + GIST)
```

**Ventajas**:
- Consultas con Ã­ndices espaciales: milisegundos
- Integridad referencial completa
- Concurrencia transaccional
- DeduplicaciÃ³n automÃ¡tica

---

## ğŸ—„ï¸ Esquema de Base de Datos (PostgreSQL + PostGIS)

### Estructura de Tablas

```sql
-- Habilitar PostGIS
CREATE EXTENSION IF NOT EXISTS postgis;

-- 1. Tabla de Agentes (Normalizada)
CREATE TABLE agentes (
    id BIGSERIAL PRIMARY KEY,
    nombre VARCHAR(255) NOT NULL,
    telefono VARCHAR(50),
    email VARCHAR(255) UNIQUE,
    fecha_registro TIMESTAMPTZ DEFAULT now(),
    CONSTRAINT uq_agente_nombre UNIQUE (nombre)
);

-- 2. Tabla de Propiedades (Principal)
CREATE TABLE propiedades (
    id BIGSERIAL PRIMARY KEY,
    agente_id BIGINT NOT NULL REFERENCES agentes(id) ON DELETE SET NULL,

    -- Datos descriptivos
    titulo VARCHAR(255) NOT NULL,
    tipo_propiedad VARCHAR(100),
    precio_usd NUMERIC(12, 2),

    -- Datos de ubicaciÃ³n
    direccion TEXT,
    zona VARCHAR(100),
    uv VARCHAR(50),
    manzana VARCHAR(50),

    -- Columna GEOESPACIAL clave
    coordenadas GEOGRAPHY(POINT, 4326) NOT NULL,

    -- Metadatos
    fecha_publicacion TIMESTAMPTZ,
    ultima_actualizacion TIMESTAMPTZ DEFAULT now(),
    proveedor_datos VARCHAR(100),
    url_origen TEXT
);

-- 3. Tabla de Servicios (Puntos de InterÃ©s)
CREATE TABLE servicios (
    id BIGSERIAL PRIMARY KEY,
    nombre VARCHAR(255) NOT NULL,
    tipo_servicio VARCHAR(100),
    coordenadas GEOGRAPHY(POINT, 4326) NOT NULL
);
```

### Ãndices Optimizados (CrÃ­tico para Performance)

```sql
-- Ãndices espaciales GIST para bÃºsquedas por radio
CREATE INDEX idx_propiedades_coordenadas ON propiedades USING GIST (coordenadas);
CREATE INDEX idx_servicios_coordenadas ON servicios USING GIST (coordenadas);

-- Ãndices B-Tree para filtros y JOINs
CREATE INDEX idx_propiedades_agente_id ON propiedades(agente_id);
CREATE INDEX idx_propiedades_precio ON propiedades(precio_usd);
CREATE INDEX idx_propiedades_tipo ON propiedades(tipo_propiedad);
CREATE INDEX idx_propiedades_zona ON propiedades(zona);
CREATE INDEX idx_servicios_tipo ON servicios(tipo_servicio);
```

---

## ğŸ”„ TransformaciÃ³n de Consultas CrÃ­ticas

### Consulta Actual (LÃ³gica en AplicaciÃ³n)
```python
# Rendimiento: O(nÃ—m) = segundos
def buscar_propiedades_georreferenciadas(zona, precio_min, precio_max, radio_km):
    resultados = []
    for propiedad in propiedades:
        if propiedad.zona == zona and precio_min <= propiedad.precio <= precio_max:
            for servicio in servicios_urbanos:
                distancia = haversine(propiedad.coords, servicio.coords)
                if distancia <= radio_km:
                    resultados.append(propiedad)
                    break
    return resultados
```

### Nueva Consulta (PostgreSQL + PostGIS)
```sql
-- Rendimiento: milisegundos con Ã­ndices
WITH params AS (
    SELECT
        'Equipetrol' AS zona_busqueda,
        200000 AS precio_min,
        300000 AS precio_max,
        'departamento' AS tipo_busqueda,
        2000 AS distancia_max_metros -- 2km
)
SELECT
    p.id,
    p.titulo,
    p.precio_usd,
    p.direccion,
    a.nombre AS nombre_agente,
    a.telefono AS telefono_agente
FROM
    propiedades p
JOIN
    agentes a ON p.agente_id = a.id
WHERE
    p.zona = (SELECT zona_busqueda FROM params)
    AND p.precio_usd BETWEEN (SELECT precio_min FROM params) AND (SELECT precio_max FROM params)
    AND p.tipo_propiedad = (SELECT tipo_busqueda FROM params)
    -- CondiciÃ³n geoespacial: colegio cerca
    AND EXISTS (
        SELECT 1
        FROM servicios s
        WHERE s.tipo_servicio = 'colegio'
          AND ST_DWithin(p.coordenadas, s.coordenadas, (SELECT distancia_max_metros FROM params))
    )
    -- CondiciÃ³n geoespacial: hospital cerca
    AND EXISTS (
        SELECT 1
        FROM servicios s
        WHERE s.tipo_servicio = 'hospital'
          AND ST_DWithin(p.coordenadas, s.coordenadas, (SELECT distancia_max_metros FROM params))
    );
```

---

## ğŸš€ Plan de MigraciÃ³n (ETL)

### Fase 1: PreparaciÃ³n del Entorno
1. **Aprovisionar PostgreSQL** (RDS, Cloud SQL o local)
2. **Ejecutar DDL** para crear tablas e Ã­ndices
3. **Configurar conexiÃ³n** desde aplicaciÃ³n

### Fase 2: Script ETL de MigraciÃ³n

#### Paso 2.1: Migrar Agentes (DeduplicaciÃ³n)
```python
# Extraer agentes Ãºnicos del JSON
agentes_unicos = set()
for propiedad in datos_json:
    if propiedad.get('agente'):
        agentes_unicos.add(propiedad['agente'])

# Insertar en PostgreSQL
for agente_nombre in agentes_unicos:
    cursor.execute("""
        INSERT INTO agentes (nombre, telefono, email)
        VALUES (%s, %s, %s)
        ON CONFLICT (nombre) DO NOTHING
    """, (agente_nombre, telefono, email))

# Crear mapa de IDs para referencia rÃ¡pida
agente_map = {nombre: id for id, nombre in get_agentes_from_db()}
```

#### Paso 2.2: Migrar Propiedades
```python
for propiedad in datos_json:
    # Convertir coordenadas a formato PostGIS
    coords_postgis = f"ST_SetSRID(ST_MakePoint({longitud}, {latitud}), 4326)::geography"

    cursor.execute("""
        INSERT INTO propiedades (
            agente_id, titulo, tipo_propiedad, precio_usd,
            direccion, zona, uv, manzana, coordenadas,
            fecha_publicacion, proveedor_datos, url_origen
        ) VALUES (
            %s, %s, %s, %s, %s, %s, %s, %s, {coords_postgis}, %s, %s, %s
        )
    """, (
        agente_map.get(propiedad['agente']),
        propiedad['titulo'],
        propiedad['tipo_propiedad'],
        propiedad['precio'],
        propiedad['direccion'],
        propiedad['zona'],
        propiedad['unidad_vecinal'],
        propiedad['manzana'],
        propiedad['fecha_scraping'],
        propiedad['codigo_proveedor'],
        propiedad['url']
    ))
```

#### Paso 2.3: Migrar Servicios
```python
for servicio in servicios_json:
    coords_postgis = f"ST_SetSRID(ST_MakePoint({longitud}, {latitud}), 4326)::geography"

    cursor.execute("""
        INSERT INTO servicios (nombre, tipo_servicio, coordenadas)
        VALUES (%s, %s, {coords_postgis})
    """, (servicio['nombre'], servicio['categoria']))
```

### Fase 3: ValidaciÃ³n Post-MigraciÃ³n
```sql
-- Verificar conteos
SELECT COUNT(*) FROM propiedades; -- debe coincidir con JSON
SELECT COUNT(*) FROM servicios; -- debe coincidir con JSON

-- Validar relaciones
SELECT p.titulo, a.nombre
FROM propiedades p
JOIN agentes a ON p.agente_id = a.id
WHERE p.id = 123;

-- Probar consulta geoespacial
SELECT COUNT(*)
FROM propiedades
WHERE ST_DWithin(coordenadas, ST_MakePoint(-63.182, -17.783)::geography, 2000);
```

---

## ğŸ”§ RefactorizaciÃ³n de la AplicaciÃ³n

### Motor de RecomendaciÃ³n Actualizado
```python
class RecommendationEnginePostGIS:
    def __init__(self, db_connection):
        self.db = db_connection

    def buscar_propiedades_georreferenciadas(self, criterios):
        query = """
        WITH params AS (
            SELECT %s AS zona_busqueda, %s AS precio_min,
                   %s AS precio_max, %s AS tipo_busqueda, %s AS distancia_max
        )
        SELECT p.*, a.nombre as agente_nombre
        FROM propiedades p
        JOIN agentes a ON p.agente_id = a.id
        WHERE p.zona = (SELECT zona_busqueda FROM params)
          AND p.precio_usd BETWEEN (SELECT precio_min FROM params) AND (SELECT precio_max FROM params)
          AND p.tipo_propiedad = (SELECT tipo_busqueda FROM params)
        """

        # Agregar condiciones de servicios dinÃ¡micamente
        for tipo_servicio in criterios['servicios_requeridos']:
            query += f"""
            AND EXISTS (
                SELECT 1 FROM servicios s
                WHERE s.tipo_servicio = '{tipo_servicio}'
                  AND ST_DWithin(p.coordenadas, s.coordenadas, (SELECT distancia_max FROM params))
            )
            """

        return self.db.execute(query, criterios.values()).fetchall()
```

---

## ğŸ›¡ï¸ Plan de Rollback

### Estrategia de Seguridad
1. **Mantener Sistema JSON**: No eliminar archivos originales
2. **ConfiguraciÃ³n Switchable**: Variable de entorno para cambiar fuente de datos
3. **Ventana de DecisiÃ³n**: 24-48 horas para validaciÃ³n final
4. **Rollback InstantÃ¡neo**: Cambiar configuraciÃ³n y reiniciar aplicaciÃ³n

### ImplementaciÃ³n
```python
# config.py
USE_POSTGRES = os.getenv('USE_POSTGRES', 'false').lower() == 'true'

# data_source.py
if USE_POSTGRES:
    from .postgres_source import PostgresDataSource
    data_source = PostgresDataSource()
else:
    from .json_source import JsonDataSource
    data_source = JsonDataSource()
```

---

## ğŸ“ˆ MÃ©tricas de Ã‰xito y ValidaciÃ³n

### MÃ©tricas TÃ©cnicas
- **Performance**: Consultas geoespaciales <100ms (vs segundos actuales)
- **Data Integrity**: 100% de registros migrados exitosamente
- **Index Usage**: Queries usando Ã­ndices GIST y B-Tree
- **Concurrent Users**: Soportar mÃºltiples usuarios sin bloqueos

### MÃ©tricas de Negocio
- **Response Time**: ReducciÃ³n 90% en tiempos de respuesta
- **System Availability**: 99.9% uptime con transacciones ACID
- **Data Quality**: DeduplicaciÃ³n automÃ¡tica de agentes
- **Scalability**: Capacidad para 10x datos sin degradaciÃ³n

### ValidaciÃ³n Automatizada
```python
def validate_migration():
    # Comparar conteos
    json_count = len(load_json_properties())
    pg_count = execute_query("SELECT COUNT(*) FROM propiedades")[0][0]
    assert json_count == pg_count, f"Mismatch: {json_count} vs {pg_count}"

    # Probar rendimiento
    start_time = time.time()
    results = execute_test_query()
    end_time = time.time()

    assert (end_time - start_time) < 0.1, "Query too slow: >100ms"

    # Validar integridad espacial
    invalid_coords = execute_query("""
        SELECT COUNT(*) FROM propiedades
        WHERE NOT ST_IsValid(coordenadas)
    """)[0][0]
    assert invalid_coords == 0, f"Invalid coordinates: {invalid_coords}"
```

---

## ğŸ“ Nueva Estructura del Proyecto

```
citrino-clean/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ CHANGELOG.md âœ…
â”‚   â”œâ”€â”€ SCRUM_BOARD.md âœ…
â”‚   â”œâ”€â”€ COMMITS_PLAN.md âœ…
â”‚   â”œâ”€â”€ WORKFLOW.md âœ…
â”‚   â”œâ”€â”€ DATA_ARCHITECTURE.md âœ… (actualizado)
â”‚   â””â”€â”€ MIGRATION_PLAN.md (nuevo)
â”œâ”€â”€ migration/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ etl_agentes.py
â”‚   â”‚   â”œâ”€â”€ etl_propiedades.py
â”‚   â”‚   â”œâ”€â”€ etl_servicios.py
â”‚   â”‚   â””â”€â”€ validate_migration.py
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ 01_create_schema.sql
â”‚   â”‚   â”œâ”€â”€ 02_create_indexes.sql
â”‚   â”‚   â””â”€â”€ 03_sample_queries.sql
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ database_config.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ recommendation_engine_postgis.py
â”‚   â”œâ”€â”€ database_connector.py
â”‚   â””â”€â”€ [archivos existentes actualizados]
â””â”€â”€ data/
    â”œâ”€â”€ base_datos_relevamiento.json (backup)
    â”œâ”€â”€ guia_urbana_municipal_completa.json (backup)
    â””â”€â”€ archived/ (versiones antiguas)
```

---

## ğŸ¯ PrÃ³ximos Pasos del Sprint

1. **Commit 1**: Completar documentaciÃ³n actualizada âœ“
2. **Commit 2**: Limpieza y preparaciÃ³n para migraciÃ³n
3. **Commit 3**: Implementar scripts ETL bÃ¡sicos
4. **Commit 4**: Crear DDL completo de PostgreSQL
5. **Commit 5**: Refactorizar motor de recomendaciÃ³n
6. **Commit 6**: Ejecutar migraciÃ³n completa
7. **Commit 7**: Configurar sistema de rollback

---

## ğŸ”„ Impacto en el Sistema Actual

### Cambios Inmediatos
- **Recomendation Engine**: MigraciÃ³n de Haversine Python a PostGIS
- **API Server**: Nuevos endpoints para consultas PostgreSQL
- **ETL Process**: Sistema de procesamiento de datos
- **Configuration**: Sistema switching JSON/PostgreSQL

### Beneficios a Largo Plazo
- **Performance**: Mejora exponencial en consultas geoespaciales
- **Scalability**: Preparado para crecimiento 10x
- **Maintainability**: Base de datos relacional vs archivos JSON
- **Analytics**: Capacidades avanzadas de consulta SQL

---

---

## ğŸ¤– IntegraciÃ³n con Chatbot UI (v2.1.0)

### Sistema Conversacional
El nuevo chatbot profesional integrado en v2.1.0 utiliza la arquitectura de datos actual (JSON) pero estÃ¡ preparado para migraciÃ³n PostgreSQL:

```python
# api/chatbot_completions.py
class CitrinoChatbotAPI:
    def __init__(self):
        self.propiedades = self._load_properties()  # JSON actual
        self.recommendation_engine = RecommendationEngineMejorado()

    def generate_property_search_response(self, entities):
        # Sistema hÃ­brido actual - pronto migrarÃ¡ a PostgreSQL
        if self.recommendation_engine:
            recomendaciones = self.recommendation_engine.generar_recomendaciones(
                perfil, limite=5, umbral_minimo=0.01
            )
```

### PreparaciÃ³n para MigraciÃ³n
- **Data source abstraction**: Capa de abstracciÃ³n lista para PostgreSQL
- **API endpoints consistentes**: Mismos endpoints durante y post-migraciÃ³n
- **Performance monitoring**: MÃ©tricas actuales baseline vs mejoras PostgreSQL esperadas

### Beneficios Esperados con PostgreSQL
- **Chatbot response time**: De 2s â†’ <200ms con consultas PostGIS
- **Concurrent users**: Soporte multiusuario sin bloqueos
- **Advanced queries**: BÃºsqueda geoespacial compleja en tiempo real
- **Data freshness**: Actualizaciones incrementales concurrentes

---

*Ãšltima actualizaciÃ³n: 2025-10-15 (con integraciÃ³n Chatbot UI v2.1.0)*
**Estado actual**: Chatbot UI operativo con JSON, migraciÃ³n PostgreSQL preparada