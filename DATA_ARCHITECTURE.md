# üèóÔ∏è Arquitectura de Datos - Migraci√≥n a PostgreSQL + PostGIS

Documentaci√≥n completa de la migraci√≥n desde JSON centralizado a PostgreSQL + PostGIS basada en investigaci√≥n experta de Tongyi.

---

## üéØ Resumen Ejecutivo

**Decisi√≥n Estrat√©gica**: Migraci√≥n de archivos JSON a PostgreSQL + PostGIS
**Fuente**: Investigaci√≥n detallada con Tongyi (LLM especializado)
**Objetivo**: Resolver limitaciones de rendimiento, escalabilidad y consistencia
**Resultado Esperado**: Consultas geoespaciales de segundos ‚Üí milisegundos

### Beneficios Clave
- **Rendimiento**: Reducci√≥n dr√°stica en tiempos de respuesta geoespacial
- **Escalabilidad**: Capacidad para 10x crecimiento sin degradaci√≥n
- **Integridad**: Consistencia ACID con claves for√°neas
- **Capacidades Anal√≠ticas**: Consultas complejas relacionales + espaciales

---

## üìä Estado Actual vs Propuesto

### Arquitectura Actual (JSON)
```
data/
‚îú‚îÄ‚îÄ base_datos_relevamiento.json    # 1,588 propiedades
‚îî‚îÄ‚îÄ guia_urbana_municipal_completa.json  # 4,777 servicios
```

**Limitaciones Cr√≠ticas**:
- Consultas O(n√óm): 7,585,876 c√°lculos por b√∫squeda
- Sin concurrencia en actualizaciones
- Duplicaci√≥n de datos de agentes
- Performance: segundos por consulta geoespacial

### Arquitectura Propuesta (PostgreSQL + PostGIS)
```
PostgreSQL Database:
‚îú‚îÄ‚îÄ agentes (tabla normalizada)
‚îú‚îÄ‚îÄ propiedades (con coordenadas GEOGRAPHY)
‚îú‚îÄ‚îÄ servicios (con √≠ndices espaciales GIST)
‚îî‚îÄ‚îÄ √çndices optimizados (B-Tree + GIST)
```

**Ventajas**:
- Consultas con √≠ndices espaciales: milisegundos
- Integridad referencial completa
- Concurrencia transaccional
- Deduplicaci√≥n autom√°tica

---

## üóÑÔ∏è Esquema de Base de Datos (PostgreSQL + PostGIS)

### Estructura de Tablas

```sql
-- Habilitar PostGIS
CREATE EXTENSION IF NOT EXISTS postgis;

-- 1. Tabla de Agentes (Normalizada)
CREATE TABLE agentes (
    id BIGSERIAL PRIMARY KEY,
    nombre VARCHAR(255) NOT NULL,
    telefono VARCHAR(50),
    email VARCHAR(255) UNIQUE,
    fecha_registro TIMESTAMPTZ DEFAULT now(),
    CONSTRAINT uq_agente_nombre UNIQUE (nombre)
);

-- 2. Tabla de Propiedades (Principal)
CREATE TABLE propiedades (
    id BIGSERIAL PRIMARY KEY,
    agente_id BIGINT NOT NULL REFERENCES agentes(id) ON DELETE SET NULL,

    -- Datos descriptivos
    titulo VARCHAR(255) NOT NULL,
    tipo_propiedad VARCHAR(100),
    precio_usd NUMERIC(12, 2),

    -- Datos de ubicaci√≥n
    direccion TEXT,
    zona VARCHAR(100),
    uv VARCHAR(50),
    manzana VARCHAR(50),

    -- Columna GEOESPACIAL clave
    coordenadas GEOGRAPHY(POINT, 4326) NOT NULL,

    -- Metadatos
    fecha_publicacion TIMESTAMPTZ,
    ultima_actualizacion TIMESTAMPTZ DEFAULT now(),
    proveedor_datos VARCHAR(100),
    url_origen TEXT
);

-- 3. Tabla de Servicios (Puntos de Inter√©s)
CREATE TABLE servicios (
    id BIGSERIAL PRIMARY KEY,
    nombre VARCHAR(255) NOT NULL,
    tipo_servicio VARCHAR(100),
    coordenadas GEOGRAPHY(POINT, 4326) NOT NULL
);
```

### √çndices Optimizados (Cr√≠tico para Performance)

```sql
-- √çndices espaciales GIST para b√∫squedas por radio
CREATE INDEX idx_propiedades_coordenadas ON propiedades USING GIST (coordenadas);
CREATE INDEX idx_servicios_coordenadas ON servicios USING GIST (coordenadas);

-- √çndices B-Tree para filtros y JOINs
CREATE INDEX idx_propiedades_agente_id ON propiedades(agente_id);
CREATE INDEX idx_propiedades_precio ON propiedades(precio_usd);
CREATE INDEX idx_propiedades_tipo ON propiedades(tipo_propiedad);
CREATE INDEX idx_propiedades_zona ON propiedades(zona);
CREATE INDEX idx_servicios_tipo ON servicios(tipo_servicio);
```

---

## üîÑ Transformaci√≥n de Consultas Cr√≠ticas

### Consulta Actual (L√≥gica en Aplicaci√≥n)
```python
# Rendimiento: O(n√óm) = segundos
def buscar_propiedades_georreferenciadas(zona, precio_min, precio_max, radio_km):
    resultados = []
    for propiedad in propiedades:
        if propiedad.zona == zona and precio_min <= propiedad.precio <= precio_max:
            for servicio in servicios_urbanos:
                distancia = haversine(propiedad.coords, servicio.coords)
                if distancia <= radio_km:
                    resultados.append(propiedad)
                    break
    return resultados
```

### Nueva Consulta (PostgreSQL + PostGIS)
```sql
-- Rendimiento: milisegundos con √≠ndices
WITH params AS (
    SELECT
        'Equipetrol' AS zona_busqueda,
        200000 AS precio_min,
        300000 AS precio_max,
        'departamento' AS tipo_busqueda,
        2000 AS distancia_max_metros -- 2km
)
SELECT
    p.id,
    p.titulo,
    p.precio_usd,
    p.direccion,
    a.nombre AS nombre_agente,
    a.telefono AS telefono_agente
FROM
    propiedades p
JOIN
    agentes a ON p.agente_id = a.id
WHERE
    p.zona = (SELECT zona_busqueda FROM params)
    AND p.precio_usd BETWEEN (SELECT precio_min FROM params) AND (SELECT precio_max FROM params)
    AND p.tipo_propiedad = (SELECT tipo_busqueda FROM params)
    -- Condici√≥n geoespacial: colegio cerca
    AND EXISTS (
        SELECT 1
        FROM servicios s
        WHERE s.tipo_servicio = 'colegio'
          AND ST_DWithin(p.coordenadas, s.coordenadas, (SELECT distancia_max_metros FROM params))
    )
    -- Condici√≥n geoespacial: hospital cerca
    AND EXISTS (
        SELECT 1
        FROM servicios s
        WHERE s.tipo_servicio = 'hospital'
          AND ST_DWithin(p.coordenadas, s.coordenadas, (SELECT distancia_max_metros FROM params))
    );
```

---

## üöÄ Plan de Migraci√≥n (ETL)

### Fase 1: Preparaci√≥n del Entorno
1. **Aprovisionar PostgreSQL** (RDS, Cloud SQL o local)
2. **Ejecutar DDL** para crear tablas e √≠ndices
3. **Configurar conexi√≥n** desde aplicaci√≥n

### Fase 2: Script ETL de Migraci√≥n

#### Paso 2.1: Migrar Agentes (Deduplicaci√≥n)
```python
# Extraer agentes √∫nicos del JSON
agentes_unicos = set()
for propiedad in datos_json:
    if propiedad.get('agente'):
        agentes_unicos.add(propiedad['agente'])

# Insertar en PostgreSQL
for agente_nombre in agentes_unicos:
    cursor.execute("""
        INSERT INTO agentes (nombre, telefono, email)
        VALUES (%s, %s, %s)
        ON CONFLICT (nombre) DO NOTHING
    """, (agente_nombre, telefono, email))

# Crear mapa de IDs para referencia r√°pida
agente_map = {nombre: id for id, nombre in get_agentes_from_db()}
```

#### Paso 2.2: Migrar Propiedades
```python
for propiedad in datos_json:
    # Convertir coordenadas a formato PostGIS
    coords_postgis = f"ST_SetSRID(ST_MakePoint({longitud}, {latitud}), 4326)::geography"

    cursor.execute("""
        INSERT INTO propiedades (
            agente_id, titulo, tipo_propiedad, precio_usd,
            direccion, zona, uv, manzana, coordenadas,
            fecha_publicacion, proveedor_datos, url_origen
        ) VALUES (
            %s, %s, %s, %s, %s, %s, %s, %s, {coords_postgis}, %s, %s, %s
        )
    """, (
        agente_map.get(propiedad['agente']),
        propiedad['titulo'],
        propiedad['tipo_propiedad'],
        propiedad['precio'],
        propiedad['direccion'],
        propiedad['zona'],
        propiedad['unidad_vecinal'],
        propiedad['manzana'],
        propiedad['fecha_scraping'],
        propiedad['codigo_proveedor'],
        propiedad['url']
    ))
```

#### Paso 2.3: Migrar Servicios
```python
for servicio in servicios_json:
    coords_postgis = f"ST_SetSRID(ST_MakePoint({longitud}, {latitud}), 4326)::geography"

    cursor.execute("""
        INSERT INTO servicios (nombre, tipo_servicio, coordenadas)
        VALUES (%s, %s, {coords_postgis})
    """, (servicio['nombre'], servicio['categoria']))
```

### Fase 3: Validaci√≥n Post-Migraci√≥n
```sql
-- Verificar conteos
SELECT COUNT(*) FROM propiedades; -- debe coincidir con JSON
SELECT COUNT(*) FROM servicios; -- debe coincidir con JSON

-- Validar relaciones
SELECT p.titulo, a.nombre
FROM propiedades p
JOIN agentes a ON p.agente_id = a.id
WHERE p.id = 123;

-- Probar consulta geoespacial
SELECT COUNT(*)
FROM propiedades
WHERE ST_DWithin(coordenadas, ST_MakePoint(-63.182, -17.783)::geography, 2000);
```

---

## üîß Refactorizaci√≥n de la Aplicaci√≥n

### Motor de Recomendaci√≥n Actualizado
```python
class RecommendationEnginePostGIS:
    def __init__(self, db_connection):
        self.db = db_connection

    def buscar_propiedades_georreferenciadas(self, criterios):
        query = """
        WITH params AS (
            SELECT %s AS zona_busqueda, %s AS precio_min,
                   %s AS precio_max, %s AS tipo_busqueda, %s AS distancia_max
        )
        SELECT p.*, a.nombre as agente_nombre
        FROM propiedades p
        JOIN agentes a ON p.agente_id = a.id
        WHERE p.zona = (SELECT zona_busqueda FROM params)
          AND p.precio_usd BETWEEN (SELECT precio_min FROM params) AND (SELECT precio_max FROM params)
          AND p.tipo_propiedad = (SELECT tipo_busqueda FROM params)
        """

        # Agregar condiciones de servicios din√°micamente
        for tipo_servicio in criterios['servicios_requeridos']:
            query += f"""
            AND EXISTS (
                SELECT 1 FROM servicios s
                WHERE s.tipo_servicio = '{tipo_servicio}'
                  AND ST_DWithin(p.coordenadas, s.coordenadas, (SELECT distancia_max FROM params))
            )
            """

        return self.db.execute(query, criterios.values()).fetchall()
```

---

## üõ°Ô∏è Plan de Rollback

### Estrategia de Seguridad
1. **Mantener Sistema JSON**: No eliminar archivos originales
2. **Configuraci√≥n Switchable**: Variable de entorno para cambiar fuente de datos
3. **Ventana de Decisi√≥n**: 24-48 horas para validaci√≥n final
4. **Rollback Instant√°neo**: Cambiar configuraci√≥n y reiniciar aplicaci√≥n

### Implementaci√≥n
```python
# config.py
USE_POSTGRES = os.getenv('USE_POSTGRES', 'false').lower() == 'true'

# data_source.py
if USE_POSTGRES:
    from .postgres_source import PostgresDataSource
    data_source = PostgresDataSource()
else:
    from .json_source import JsonDataSource
    data_source = JsonDataSource()
```

---

## üìà M√©tricas de √âxito y Validaci√≥n

### M√©tricas T√©cnicas
- **Performance**: Consultas geoespaciales <100ms (vs segundos actuales)
- **Data Integrity**: 100% de registros migrados exitosamente
- **Index Usage**: Queries usando √≠ndices GIST y B-Tree
- **Concurrent Users**: Soportar m√∫ltiples usuarios sin bloqueos

### M√©tricas de Negocio
- **Response Time**: Reducci√≥n 90% en tiempos de respuesta
- **System Availability**: 99.9% uptime con transacciones ACID
- **Data Quality**: Deduplicaci√≥n autom√°tica de agentes
- **Scalability**: Capacidad para 10x datos sin degradaci√≥n

### Validaci√≥n Automatizada
```python
def validate_migration():
    # Comparar conteos
    json_count = len(load_json_properties())
    pg_count = execute_query("SELECT COUNT(*) FROM propiedades")[0][0]
    assert json_count == pg_count, f"Mismatch: {json_count} vs {pg_count}"

    # Probar rendimiento
    start_time = time.time()
    results = execute_test_query()
    end_time = time.time()

    assert (end_time - start_time) < 0.1, "Query too slow: >100ms"

    # Validar integridad espacial
    invalid_coords = execute_query("""
        SELECT COUNT(*) FROM propiedades
        WHERE NOT ST_IsValid(coordenadas)
    """)[0][0]
    assert invalid_coords == 0, f"Invalid coordinates: {invalid_coords}"
```

---

## üìÅ Nueva Estructura del Proyecto

```
citrino-clean/
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ CHANGELOG.md ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ SCRUM_BOARD.md ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ COMMITS_PLAN.md ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ WORKFLOW.md ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ DATA_ARCHITECTURE.md ‚úÖ (actualizado)
‚îÇ   ‚îî‚îÄ‚îÄ MIGRATION_PLAN.md (nuevo)
‚îú‚îÄ‚îÄ migration/
‚îÇ   ‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ etl_agentes.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ etl_propiedades.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ etl_servicios.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validate_migration.py
‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_create_schema.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_create_indexes.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 03_sample_queries.sql
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îî‚îÄ‚îÄ database_config.py
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ recommendation_engine_postgis.py
‚îÇ   ‚îú‚îÄ‚îÄ database_connector.py
‚îÇ   ‚îî‚îÄ‚îÄ [archivos existentes actualizados]
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ base_datos_relevamiento.json (backup)
    ‚îú‚îÄ‚îÄ guia_urbana_municipal_completa.json (backup)
    ‚îî‚îÄ‚îÄ archived/ (versiones antiguas)
```

---

## üéØ Pr√≥ximos Pasos del Sprint

1. **Commit 1**: Completar documentaci√≥n actualizada ‚úì
2. **Commit 2**: Limpieza y preparaci√≥n para migraci√≥n
3. **Commit 3**: Implementar scripts ETL b√°sicos
4. **Commit 4**: Crear DDL completo de PostgreSQL
5. **Commit 5**: Refactorizar motor de recomendaci√≥n
6. **Commit 6**: Ejecutar migraci√≥n completa
7. **Commit 7**: Configurar sistema de rollback

---

## üîÑ Impacto en el Sistema Actual

### Cambios Inmediatos
- **Recomendation Engine**: Migraci√≥n de Haversine Python a PostGIS
- **API Server**: Nuevos endpoints para consultas PostgreSQL
- **ETL Process**: Sistema de procesamiento de datos
- **Configuration**: Sistema switching JSON/PostgreSQL

### Beneficios a Largo Plazo
- **Performance**: Mejora exponencial en consultas geoespaciales
- **Scalability**: Preparado para crecimiento 10x
- **Maintainability**: Base de datos relacional vs archivos JSON
- **Analytics**: Capacidades avanzadas de consulta SQL

---

---

## ü§ñ Integraci√≥n con Chatbot UI (v2.1.0)

### Sistema Conversacional
El nuevo chatbot profesional integrado en v2.1.0 utiliza la arquitectura de datos actual (JSON) pero est√° preparado para migraci√≥n PostgreSQL:

```python
# api/chatbot_completions.py
class CitrinoChatbotAPI:
    def __init__(self):
        self.propiedades = self._load_properties()  # JSON actual
        self.recommendation_engine = RecommendationEngineMejorado()

    def generate_property_search_response(self, entities):
        # Sistema h√≠brido actual - pronto migrar√° a PostgreSQL
        if self.recommendation_engine:
            recomendaciones = self.recommendation_engine.generar_recomendaciones(
                perfil, limite=5, umbral_minimo=0.01
            )
```

### Preparaci√≥n para Migraci√≥n
- **Data source abstraction**: Capa de abstracci√≥n lista para PostgreSQL
- **API endpoints consistentes**: Mismos endpoints durante y post-migraci√≥n
- **Performance monitoring**: M√©tricas actuales baseline vs mejoras PostgreSQL esperadas

### Beneficios Esperados con PostgreSQL
- **Chatbot response time**: De 2s ‚Üí <200ms con consultas PostGIS
- **Concurrent users**: Soporte multiusuario sin bloqueos
- **Advanced queries**: B√∫squeda geoespacial compleja en tiempo real
- **Data freshness**: Actualizaciones incrementales concurrentes

---

*√öltima actualizaci√≥n: 2025-10-15 (con integraci√≥n Chatbot UI v2.1.0)*
**Estado actual**: Chatbot UI operativo con JSON, migraci√≥n PostgreSQL preparada