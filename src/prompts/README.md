# Sistema de Prompts y Restricciones LLM - Citrino

Documentaci√≥n completa del sistema de prompts, restricciones y configuraciones para controlar el comportamiento de los modelos de lenguaje en Citrino.

## üìã Overview

El sistema de prompts de Citrino est√° dise√±ado para:

- **Reducir alucinaciones** mediante restricciones estrictas
- **Limitar respuestas** a datos existentes en la base de datos
- **Controlar temperatura** para mantener consistencia
- **Validar informaci√≥n** en tiempo real
- **Prevenir especulaciones** y promesas irreales

## üóÇÔ∏è Estructura de Archivos

```
src/prompts/
‚îú‚îÄ‚îÄ system_prompt_chat.py        # System prompts para Citrino Chat
‚îú‚îÄ‚îÄ system_prompt_reco.py        # System prompts para Citrino Reco
‚îú‚îÄ‚îÄ llm_config.py               # Configuraci√≥n centralizada de LLM
‚îú‚îÄ‚îÄ data_restrictions.py        # Restricciones de datos y fuentes
‚îî‚îÄ‚îÄ README.md                   # Esta documentaci√≥n
```

## üå°Ô∏è Configuraci√≥n de Temperatura

### Temperatura Ultra-Baja: 0.05 - 0.1
- **Chat**: 0.05 (m√°xima consistencia)
- **Reco**: 0.1 (consistencia con c√°lculos)
- **Prop√≥sito**: Respuestas predecibles y basadas en datos

### L√≠mites de Tokens
- **Chat**: 250 tokens m√°ximo (respuestas breves)
- **Reco**: 400 tokens m√°ximo (recomendaciones detalladas)
- **General**: 300 tokens m√°ximo

## üîí Restricciones Principales

### 1. Fuentes de Datos Permitidas
```python
ALLOWED_DATA_SOURCES = {
    "primary_database": "base_datos_relevamiento.json",
    "urban_guide": "guia_urbana_municipal_completa.json"
}
```

### 2. Zonas Autorizadas
- **Equipetrol**: $200k - $800k
- **Urbari**: $350k - $1.5M
- **Santa M√≥nica**: $80k - $400k
- **Las Palmas**: $150k - $600k
- **Santiago**: $100k - $500k
- **Sacta**: $70k - $300k
- **Pampa de la Isla**: $60k - $250k

### 3. Tipos de Propiedad Permitidos
- **Casa**: 60-1000m¬≤, 1-6 habitaciones, $50k-$2M
- **Departamento**: 30-300m¬≤, 1-4 habitaciones, $50k-$1M
- **Terreno**: 100-5000m¬≤, $30k-$2M
- **Duplex**: 80-400m¬≤, 2-5 habitaciones, $100k-$1.5M
- **Loft**: 40-200m¬≤, 1-2 habitaciones, $80k-$600k

### 4. Palabras Prohibidas
- **Garant√≠as**: "garantizado", "seguro", "100%"
- **Especulaci√≥n**: "plusval√≠a garantida", "rentabilidad segura"
- **Subjetividad**: "perfecto", "excelente", "mejor"
- **Presi√≥n**: "urgente", "oportunidad √∫nica", "no te lo pierdas"

## üìù System Prompts

### Citrino Chat - Principios Clave

1. **Solo Datos Existentes**: Responder √∫nicamente con informaci√≥n de la BD
2. **Verificaci√≥n Obligatoria**: Validar cada dato mencionado
3. **Transparencia**: Admitir limitaciones de informaci√≥n
4. **Sin Promesas**: Evitar garant√≠as o predicciones futuras

#### Ejemplo de Prompt:
```python
"Eres un asistente de inversi√≥n inmobiliaria especializado para Citrino Bolivia.
Tu funci√≥n es proporcionar informaci√≥n √öNICAMENTE basada en los datos existentes
en nuestra base de datos. Si no tienes informaci√≥n, di claramente
'No tengo datos sobre esa consulta'."
```

### Citrino Reco - Principios Clave

1. **Propiedades Reales**: Solo recomendar propiedades existentes
2. **Compatibilidad Calculada**: F√≥rmula matem√°tica estricta
3. **Justificaciones Basadas en Datos**: Solo caracter√≠sticas verificables
4. **L√≠mites Estrictos**: M√°ximo 5 recomendaciones, 60-95% compatibilidad

#### Ejemplo de Prompt:
```python
"Eres el motor de recomendaciones de Citrino Bolivia.
Tu funci√≥n es generar recomendaciones √öNICAMENTE basadas en propiedades
existententes en nuestra base de datos. Cada recomendaci√≥n debe corresponder
a una propiedad real con ID."
```

## üõ°Ô∏è Validaci√≥n de Datos

### Validaci√≥n en Tiempo Real
```python
class DataValidator:
    @staticmethod
    def validate_zone(zone_name: str) -> bool
    @staticmethod
    def validate_price(price: float, prop_type: str, zone: str) -> bool
    @staticmethod
    def validate_property_data(property_data: dict) -> dict
```

### Reglas de Validaci√≥n
- **Campos Requeridos**: id, precio, zona, tipo
- **Rangos Num√©ricos**: Verificar l√≠mites de precios y caracter√≠sticas
- **Existencia en BD**: Confirmar que los datos existen
- **Consistencia**: Validar relaciones entre datos

## ‚öôÔ∏è Configuraci√≥n LLM

### Par√°metros por Componente

#### Chat Configuration
```python
CITRINO_CHAT_LLM_CONFIG = {
    "temperature": 0.05,        # Ultra-baja
    "max_tokens": 250,          # Respuestas breves
    "validate_facts": True,     # Validaci√≥n activa
    "check_hallucinations": True
}
```

#### Reco Configuration
```python
CITRINO_RECO_LLM_CONFIG = {
    "temperature": 0.1,         # Baja
    "max_tokens": 400,          # Recomendaciones detalladas
    "validate_budget": True,     # Validar presupuesto
    "validate_compatibility": True
}
```

### Seguridad y Control
- **Safe Mode**: Activado por defecto
- **Content Filter**: Filtrado de contenido inapropiado
- **Rate Limiting**: 60 solicitudes por minuto
- **Timeout**: 30 segundos por solicitud

## üìä M√©tricas y Monitoreo

### M√©tricas Clave
- **Response Time**: Tiempo de respuesta (objetivo: <5s)
- **Success Rate**: Tasa de √©xito (objetivo: >95%)
- **Hallucination Rate**: Tasa de alucinaciones (objetivo: <5%)
- **Data Accuracy Rate**: Precisi√≥n de datos (objetivo: >80%)

### Alertas Autom√°ticas
- **Response Time > 5s**: Alerta de rendimiento
- **Error Rate > 10%**: Alerta de calidad
- **Hallucination Rate > 5%**: Alerta cr√≠tica
- **Data Accuracy < 80%**: Alerta de validaci√≥n

## üîß Implementaci√≥n

### Integraci√≥n con LLM
```python
from src.prompts.llm_config import get_llm_config
from src.prompts.data_restrictions import DataValidator

# Obtener configuraci√≥n
chat_config = get_llm_config('chat')

# Validar datos
validator = DataValidator()
validation = validator.validate_property_data(property_data)

# Usar solo si la validaci√≥n es exitosa
if validation['valid']:
    # Procesar con LLM
    pass
```

### Uso en C√≥digo
```python
# Para Chat
from src.prompts.system_prompt_chat import CITRINO_CHAT_SYSTEM_PROMPT

# Para Reco
from src.prompts.system_prompt_reco import CITRINO_RECO_SYSTEM_PROMPT

# Para Configuraci√≥n
from src.prompts.llm_config import get_llm_config
```

## üöÄ Gu√≠a de Uso R√°pido

### 1. Configurar Ambiente
```bash
# Verificar archivos de prompts
ls src/prompts/

# Probar configuraci√≥n
python src/prompts/llm_config.py
```

### 2. Implementar en LLM
```python
# Importar configuraci√≥n
from src.prompts.llm_config import get_llm_config

# Obtener config para componente
config = get_llm_config('chat')

# Aplicar a llamada LLM
response = llm_client.chat.completions.create(
    model="glm-4.6",
    messages=[{"role": "system", "content": config["system_prompt"]}],
    temperature=config["temperature"],
    max_tokens=config["max_tokens"]
)
```

### 3. Validar Respuestas
```python
from src.prompts.data_restrictions import DataValidator

validator = DataValidator()
forbidden_words = validator.check_forbidden_words(response.text)
if forbidden_words:
    # Manejar palabras prohibidas
    pass
```

## üìà Mejoras Futuras

### Planeado
- [ ] Integraci√≥n con m√°s modelos LLM
- [ ] Sistema de aprendizaje autom√°tico para detecci√≥n de alucinaciones
- [ ] M√©tricas avanzadas de calidad
- [ ] Sistema de feedback continuo

### Consideraciones
- **Scalability**: Sistema dise√±ado para escalar horizontalmente
- **Maintainability**: Configuraci√≥n centralizada y modular
- **Security**: Validaci√≥n y filtros en m√∫ltiples capas
- **Performance**: Optimizaci√≥n para respuestas r√°pidas

## üÜò Troubleshooting

### Problemas Comunes

#### 1. Alucinaciones Detectadas
**S√≠ntoma**: El sistema detecta datos inventados
**Soluci√≥n**:
- Reducir temperatura a 0.0
- Reforzar prompts de validaci√≥n
- Revisar base de datos

#### 2. Respuestas Vac√≠as
**S√≠ntoma**: El LLM no genera respuestas
**Soluci√≥n**:
- Aumentar max_tokens
- Verificar que la consulta tenga datos en BD
- Revisar prompts demasiado restrictivos

#### 3. Tiempos de Respuesta Lentos
**S√≠ntoma**: Las respuestas tardan m√°s de 5 segundos
**Soluci√≥n**:
- Reducir max_tokens
- Optimizar validaci√≥n de datos
- Considerar cache de respuestas

### Debug Mode
```python
# Activar logging detallado
import logging
logging.basicConfig(level=logging.DEBUG)

# Ver configuraci√≥n
from src.prompts.llm_config import print_config_summary
print_config_summary('chat')
```

## üìû Soporte

Para problemas con el sistema de prompts:

1. **Revisar logs**: Buscar errores en `logs/llm_errors.log`
2. **Validar configuraci√≥n**: Usar `python src/prompts/llm_config.py`
3. **Test de validaci√≥n**: Probar con `python src/prompts/data_restrictions.py`
4. **Documentation**: Revisar esta documentaci√≥n y comentarios en c√≥digo

---

**√öltima actualizaci√≥n**: 9 de Octubre 2025
**Versi√≥n**: 1.0.0
**Citrino LLM Prompt System**